{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time, copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.utils import *\n",
    "from src.override_resnet import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fuse_model(model) -> nn.Module:\n",
    "    SingleTimeFlag = False\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__ == ResNet_quan.__name__:\n",
    "            if SingleTimeFlag == True:\n",
    "                raise ValueError(\"ResNet_quan is already fused\")\n",
    "            SingleTimeFlag = True\n",
    "            torch.quantization.fuse_modules(\n",
    "                m,\n",
    "                [\"conv1\", \"bn1\", \"relu\"],\n",
    "                inplace=True,\n",
    "            )\n",
    "\n",
    "        if type(m) == BottleNeck_quan:\n",
    "\n",
    "            torch.quantization.fuse_modules(\n",
    "                m,\n",
    "                [\n",
    "                    [\"conv1\", \"bn1\", \"relu1\"],\n",
    "                    [\"conv2\", \"bn2\", \"relu2\"],\n",
    "                    [\"conv3\", \"bn3\"],\n",
    "                ],\n",
    "                inplace=True,\n",
    "            )\n",
    "            if m.downsample is not None:\n",
    "                torch.quantization.fuse_modules(\n",
    "                    m.downsample,\n",
    "                    [\"0\", \"1\"],\n",
    "                    inplace=True,\n",
    "                )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "model = resnet50_quan(weights=pretrained_weights_mapping[50]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(_weights, _name):\n",
    "    if type(_weights) == torch.Tensor:\n",
    "        _tmp = copy.deepcopy(_weights)\n",
    "        _tmp = _tmp.flatten().numpy()\n",
    "\n",
    "    else:\n",
    "        _tmp = copy.deepcopy(_weights)\n",
    "        _tmp = _tmp.weight().int_repr().numpy()\n",
    "        _tmp = _tmp.astype(float)\n",
    "        _tmp = _tmp.flatten()\n",
    "\n",
    "    plt.hist(_tmp.flatten(), bins=256)\n",
    "    plt.xlabel(\"Weight Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Histogram of {_name}\")\n",
    "    plt.show()\n",
    "    print(_tmp.min(), _tmp.max(), _tmp.mean(), _tmp.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Acc of Reference Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the origin network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BottleNeck_quan(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (relu1): ReLU()\n",
      "  (relu2): ReLU()\n",
      "  (relu3): ReLU()\n",
      "  (add): FloatFunctional(\n",
      "    (activation_post_process): Identity()\n",
      "  )\n",
      ")\n",
      "Post Training Quantization: Eval done\n"
     ]
    }
   ],
   "source": [
    "print(model.layer1[0])\n",
    "# check_accuracy(model=model, device=\"cpu\", batch_size=25)\n",
    "print(\"Post Training Quantization: Eval done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.9180801 1.9789636 -0.0006088594 0.26923782\n"
     ]
    }
   ],
   "source": [
    "__conv1 = model.conv1.weight.data\n",
    "show_plot(__conv1, \"conv1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.5129721 1.0011052 -0.015311795 0.16769269\n"
     ]
    }
   ],
   "source": [
    "__layer1_0_conv1 = model.layer1[0].conv1.weight.data\n",
    "show_plot(__layer1_0_conv1, \"layer1_0_conv1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.43231362 1.2790387 9.732936e-07 0.040513273\n"
     ]
    }
   ],
   "source": [
    "__fc = model.fc.weight.data\n",
    "show_plot(__fc, \"fc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the fused network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 102.158986\n",
      "102.158986\n",
      "BottleNeck_quan(\n",
      "  (conv1): ConvReLU2d(\n",
      "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (bn1): Identity()\n",
      "  (conv2): ConvReLU2d(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (bn2): Identity()\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn3): Identity()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Identity()\n",
      "  )\n",
      "  (relu1): Identity()\n",
      "  (relu2): Identity()\n",
      "  (relu3): ReLU()\n",
      "  (add): FloatFunctional(\n",
      "    (activation_post_process): Identity()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model = fuse_model(model)\n",
    "print(print_size_of_model(model))\n",
    "print(model.layer1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.modules of ResNet_quan(\n",
      "  (conv1): ConvReLU2d(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (bn1): Identity()\n",
      "  (relu): Identity()\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (5): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): BottleNeck_quan(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): Identity()\n",
      "      (relu2): Identity()\n",
      "      (relu3): ReLU()\n",
      "      (add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calibration for Post-Training Static Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the Quantization Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Training Quantization Prepare: Inserting Observers\n"
     ]
    }
   ],
   "source": [
    "# model.conv1.qconfig = torch.quantization.QConfig(\n",
    "#     activation=torch.quantization.PlaceholderObserver.with_args(dtype=torch.qint8),\n",
    "#     weight=torch.quantization.PlaceholderObserver.with_args(dtype=torch.qint8),\n",
    "# )\n",
    "\n",
    "model.conv1.qconfig = None\n",
    "model.qconfig = torch.quantization.get_default_qconfig(\"x86\")\n",
    "# model.qconfig = torch.quantization.get_default_qconfig(\"x86\")\n",
    "print(\"Post Training Quantization Prepare: Inserting Observers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Training Quantization Prepare: Inserting Observers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee/miniconda3/envs/py312/lib/python3.12/site-packages/torch/ao/quantization/observer.py:220: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.quantization.prepare(model, inplace=True)\n",
    "\n",
    "print(\"Post Training Quantization Prepare: Inserting Observers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module  has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b42c180>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b42c180>})\n",
      "Module conv1 does not have a qconfig\n",
      "Module conv1.0 does not have a qconfig\n",
      "Module conv1.1 does not have a qconfig\n",
      "Module bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65f627a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65f627a0>})\n",
      "Module relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd87c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd87c0>})\n",
      "Module maxpool has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8720>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8720>})\n",
      "Module layer1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8860>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8860>})\n",
      "Module layer1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8900>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8900>})\n",
      "Module layer1.0.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd89a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd89a0>})\n",
      "Module layer1.0.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8a40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8a40>})\n",
      "Module layer1.0.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8ae0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8ae0>})\n",
      "Module layer1.0.conv1.activation_post_process does not have a qconfig\n",
      "Module layer1.0.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8b80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8b80>})\n",
      "Module layer1.0.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8c20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8c20>})\n",
      "Module layer1.0.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8cc0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8cc0>})\n",
      "Module layer1.0.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8d60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8d60>})\n",
      "Module layer1.0.conv2.activation_post_process does not have a qconfig\n",
      "Module layer1.0.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8e00>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8e00>})\n",
      "Module layer1.0.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8ea0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8ea0>})\n",
      "Module layer1.0.conv3.activation_post_process does not have a qconfig\n",
      "Module layer1.0.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8f40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8f40>})\n",
      "Module layer1.0.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8fe0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd8fe0>})\n",
      "Module layer1.0.downsample has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9080>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9080>})\n",
      "Module layer1.0.downsample.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9120>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9120>})\n",
      "Module layer1.0.downsample.0.activation_post_process does not have a qconfig\n",
      "Module layer1.0.downsample.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd91c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd91c0>})\n",
      "Module layer1.0.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9260>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9260>})\n",
      "Module layer1.0.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9300>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9300>})\n",
      "Module layer1.0.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd93a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd93a0>})\n",
      "Module layer1.0.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9440>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9440>})\n",
      "Module layer1.0.add.activation_post_process does not have a qconfig\n",
      "Module layer1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9580>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9580>})\n",
      "Module layer1.1.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9620>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9620>})\n",
      "Module layer1.1.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd96c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd96c0>})\n",
      "Module layer1.1.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9760>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9760>})\n",
      "Module layer1.1.conv1.activation_post_process does not have a qconfig\n",
      "Module layer1.1.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9800>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9800>})\n",
      "Module layer1.1.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd98a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd98a0>})\n",
      "Module layer1.1.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9940>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9940>})\n",
      "Module layer1.1.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd99e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd99e0>})\n",
      "Module layer1.1.conv2.activation_post_process does not have a qconfig\n",
      "Module layer1.1.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9a80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9a80>})\n",
      "Module layer1.1.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9b20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9b20>})\n",
      "Module layer1.1.conv3.activation_post_process does not have a qconfig\n",
      "Module layer1.1.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9bc0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9bc0>})\n",
      "Module layer1.1.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9c60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9c60>})\n",
      "Module layer1.1.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9d00>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9d00>})\n",
      "Module layer1.1.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9da0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9da0>})\n",
      "Module layer1.1.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9e40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9e40>})\n",
      "Module layer1.1.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9ee0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dd9ee0>})\n",
      "Module layer1.1.add.activation_post_process does not have a qconfig\n",
      "Module layer1.2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda020>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda020>})\n",
      "Module layer1.2.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda0c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda0c0>})\n",
      "Module layer1.2.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda160>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda160>})\n",
      "Module layer1.2.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda200>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda200>})\n",
      "Module layer1.2.conv1.activation_post_process does not have a qconfig\n",
      "Module layer1.2.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda2a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda2a0>})\n",
      "Module layer1.2.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda340>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda340>})\n",
      "Module layer1.2.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda3e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda3e0>})\n",
      "Module layer1.2.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda480>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda480>})\n",
      "Module layer1.2.conv2.activation_post_process does not have a qconfig\n",
      "Module layer1.2.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda520>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda520>})\n",
      "Module layer1.2.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda5c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda5c0>})\n",
      "Module layer1.2.conv3.activation_post_process does not have a qconfig\n",
      "Module layer1.2.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda660>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda660>})\n",
      "Module layer1.2.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda700>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda700>})\n",
      "Module layer1.2.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda7a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda7a0>})\n",
      "Module layer1.2.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda840>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda840>})\n",
      "Module layer1.2.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda8e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda8e0>})\n",
      "Module layer1.2.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda980>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65dda980>})\n",
      "Module layer1.2.add.activation_post_process does not have a qconfig\n",
      "Module layer2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddaac0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddaac0>})\n",
      "Module layer2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddab60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddab60>})\n",
      "Module layer2.0.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddac00>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddac00>})\n",
      "Module layer2.0.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddaca0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddaca0>})\n",
      "Module layer2.0.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddad40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddad40>})\n",
      "Module layer2.0.conv1.activation_post_process does not have a qconfig\n",
      "Module layer2.0.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddade0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddade0>})\n",
      "Module layer2.0.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddae80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddae80>})\n",
      "Module layer2.0.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddaf20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddaf20>})\n",
      "Module layer2.0.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddafc0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddafc0>})\n",
      "Module layer2.0.conv2.activation_post_process does not have a qconfig\n",
      "Module layer2.0.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb060>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb060>})\n",
      "Module layer2.0.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb100>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb100>})\n",
      "Module layer2.0.conv3.activation_post_process does not have a qconfig\n",
      "Module layer2.0.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb1a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb1a0>})\n",
      "Module layer2.0.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb240>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb240>})\n",
      "Module layer2.0.downsample has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb2e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb2e0>})\n",
      "Module layer2.0.downsample.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb380>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb380>})\n",
      "Module layer2.0.downsample.0.activation_post_process does not have a qconfig\n",
      "Module layer2.0.downsample.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb420>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb420>})\n",
      "Module layer2.0.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb4c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb4c0>})\n",
      "Module layer2.0.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb560>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb560>})\n",
      "Module layer2.0.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb600>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb600>})\n",
      "Module layer2.0.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb6a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb6a0>})\n",
      "Module layer2.0.add.activation_post_process does not have a qconfig\n",
      "Module layer2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb7e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb7e0>})\n",
      "Module layer2.1.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb880>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb880>})\n",
      "Module layer2.1.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb920>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb920>})\n",
      "Module layer2.1.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb9c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddb9c0>})\n",
      "Module layer2.1.conv1.activation_post_process does not have a qconfig\n",
      "Module layer2.1.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddba60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddba60>})\n",
      "Module layer2.1.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbb00>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbb00>})\n",
      "Module layer2.1.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbba0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbba0>})\n",
      "Module layer2.1.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbc40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbc40>})\n",
      "Module layer2.1.conv2.activation_post_process does not have a qconfig\n",
      "Module layer2.1.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbce0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbce0>})\n",
      "Module layer2.1.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbd80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbd80>})\n",
      "Module layer2.1.conv3.activation_post_process does not have a qconfig\n",
      "Module layer2.1.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbe20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbe20>})\n",
      "Module layer2.1.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbec0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbec0>})\n",
      "Module layer2.1.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbf60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb65ddbf60>})\n",
      "Module layer2.1.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174040>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174040>})\n",
      "Module layer2.1.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1740e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1740e0>})\n",
      "Module layer2.1.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174180>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174180>})\n",
      "Module layer2.1.add.activation_post_process does not have a qconfig\n",
      "Module layer2.2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1742c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1742c0>})\n",
      "Module layer2.2.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174360>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174360>})\n",
      "Module layer2.2.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174400>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174400>})\n",
      "Module layer2.2.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1744a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1744a0>})\n",
      "Module layer2.2.conv1.activation_post_process does not have a qconfig\n",
      "Module layer2.2.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174540>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174540>})\n",
      "Module layer2.2.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1745e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1745e0>})\n",
      "Module layer2.2.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174680>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174680>})\n",
      "Module layer2.2.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174720>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174720>})\n",
      "Module layer2.2.conv2.activation_post_process does not have a qconfig\n",
      "Module layer2.2.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1747c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1747c0>})\n",
      "Module layer2.2.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174860>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174860>})\n",
      "Module layer2.2.conv3.activation_post_process does not have a qconfig\n",
      "Module layer2.2.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174900>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174900>})\n",
      "Module layer2.2.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1749a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1749a0>})\n",
      "Module layer2.2.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174a40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174a40>})\n",
      "Module layer2.2.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174ae0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174ae0>})\n",
      "Module layer2.2.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174b80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174b80>})\n",
      "Module layer2.2.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174c20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174c20>})\n",
      "Module layer2.2.add.activation_post_process does not have a qconfig\n",
      "Module layer2.3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174d60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174d60>})\n",
      "Module layer2.3.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174e00>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174e00>})\n",
      "Module layer2.3.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174ea0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174ea0>})\n",
      "Module layer2.3.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174f40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174f40>})\n",
      "Module layer2.3.conv1.activation_post_process does not have a qconfig\n",
      "Module layer2.3.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174fe0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b174fe0>})\n",
      "Module layer2.3.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175080>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175080>})\n",
      "Module layer2.3.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175120>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175120>})\n",
      "Module layer2.3.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1751c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1751c0>})\n",
      "Module layer2.3.conv2.activation_post_process does not have a qconfig\n",
      "Module layer2.3.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175260>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175260>})\n",
      "Module layer2.3.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175300>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175300>})\n",
      "Module layer2.3.conv3.activation_post_process does not have a qconfig\n",
      "Module layer2.3.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1753a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1753a0>})\n",
      "Module layer2.3.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175440>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175440>})\n",
      "Module layer2.3.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1754e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1754e0>})\n",
      "Module layer2.3.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175580>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175580>})\n",
      "Module layer2.3.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175620>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175620>})\n",
      "Module layer2.3.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1756c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1756c0>})\n",
      "Module layer2.3.add.activation_post_process does not have a qconfig\n",
      "Module layer3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175800>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175800>})\n",
      "Module layer3.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1758a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1758a0>})\n",
      "Module layer3.0.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175940>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175940>})\n",
      "Module layer3.0.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1759e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1759e0>})\n",
      "Module layer3.0.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175a80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175a80>})\n",
      "Module layer3.0.conv1.activation_post_process does not have a qconfig\n",
      "Module layer3.0.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175b20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175b20>})\n",
      "Module layer3.0.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175bc0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175bc0>})\n",
      "Module layer3.0.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175c60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175c60>})\n",
      "Module layer3.0.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175d00>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175d00>})\n",
      "Module layer3.0.conv2.activation_post_process does not have a qconfig\n",
      "Module layer3.0.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175da0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175da0>})\n",
      "Module layer3.0.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175e40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175e40>})\n",
      "Module layer3.0.conv3.activation_post_process does not have a qconfig\n",
      "Module layer3.0.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175ee0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175ee0>})\n",
      "Module layer3.0.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175f80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b175f80>})\n",
      "Module layer3.0.downsample has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176020>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176020>})\n",
      "Module layer3.0.downsample.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1760c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1760c0>})\n",
      "Module layer3.0.downsample.0.activation_post_process does not have a qconfig\n",
      "Module layer3.0.downsample.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176160>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176160>})\n",
      "Module layer3.0.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176200>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176200>})\n",
      "Module layer3.0.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1762a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1762a0>})\n",
      "Module layer3.0.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176340>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176340>})\n",
      "Module layer3.0.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1763e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1763e0>})\n",
      "Module layer3.0.add.activation_post_process does not have a qconfig\n",
      "Module layer3.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176520>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176520>})\n",
      "Module layer3.1.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1765c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1765c0>})\n",
      "Module layer3.1.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176660>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176660>})\n",
      "Module layer3.1.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176700>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176700>})\n",
      "Module layer3.1.conv1.activation_post_process does not have a qconfig\n",
      "Module layer3.1.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1767a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1767a0>})\n",
      "Module layer3.1.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176840>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176840>})\n",
      "Module layer3.1.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1768e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1768e0>})\n",
      "Module layer3.1.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176980>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176980>})\n",
      "Module layer3.1.conv2.activation_post_process does not have a qconfig\n",
      "Module layer3.1.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176a20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176a20>})\n",
      "Module layer3.1.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176ac0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176ac0>})\n",
      "Module layer3.1.conv3.activation_post_process does not have a qconfig\n",
      "Module layer3.1.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176b60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176b60>})\n",
      "Module layer3.1.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176c00>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176c00>})\n",
      "Module layer3.1.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176ca0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176ca0>})\n",
      "Module layer3.1.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176d40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176d40>})\n",
      "Module layer3.1.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176de0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176de0>})\n",
      "Module layer3.1.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176e80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176e80>})\n",
      "Module layer3.1.add.activation_post_process does not have a qconfig\n",
      "Module layer3.2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176fc0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b176fc0>})\n",
      "Module layer3.2.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177060>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177060>})\n",
      "Module layer3.2.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177100>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177100>})\n",
      "Module layer3.2.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1771a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1771a0>})\n",
      "Module layer3.2.conv1.activation_post_process does not have a qconfig\n",
      "Module layer3.2.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177240>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177240>})\n",
      "Module layer3.2.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1772e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1772e0>})\n",
      "Module layer3.2.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177380>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177380>})\n",
      "Module layer3.2.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177420>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177420>})\n",
      "Module layer3.2.conv2.activation_post_process does not have a qconfig\n",
      "Module layer3.2.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1774c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1774c0>})\n",
      "Module layer3.2.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177560>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177560>})\n",
      "Module layer3.2.conv3.activation_post_process does not have a qconfig\n",
      "Module layer3.2.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177600>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177600>})\n",
      "Module layer3.2.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1776a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1776a0>})\n",
      "Module layer3.2.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177740>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177740>})\n",
      "Module layer3.2.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1777e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1777e0>})\n",
      "Module layer3.2.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177880>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177880>})\n",
      "Module layer3.2.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177920>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177920>})\n",
      "Module layer3.2.add.activation_post_process does not have a qconfig\n",
      "Module layer3.3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177a60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177a60>})\n",
      "Module layer3.3.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177b00>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177b00>})\n",
      "Module layer3.3.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177ba0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177ba0>})\n",
      "Module layer3.3.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177c40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177c40>})\n",
      "Module layer3.3.conv1.activation_post_process does not have a qconfig\n",
      "Module layer3.3.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177ce0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177ce0>})\n",
      "Module layer3.3.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177d80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177d80>})\n",
      "Module layer3.3.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177e20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177e20>})\n",
      "Module layer3.3.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177ec0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177ec0>})\n",
      "Module layer3.3.conv2.activation_post_process does not have a qconfig\n",
      "Module layer3.3.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177f60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b177f60>})\n",
      "Module layer3.3.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188040>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188040>})\n",
      "Module layer3.3.conv3.activation_post_process does not have a qconfig\n",
      "Module layer3.3.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1880e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1880e0>})\n",
      "Module layer3.3.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188180>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188180>})\n",
      "Module layer3.3.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188220>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188220>})\n",
      "Module layer3.3.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1882c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1882c0>})\n",
      "Module layer3.3.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188360>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188360>})\n",
      "Module layer3.3.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188400>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188400>})\n",
      "Module layer3.3.add.activation_post_process does not have a qconfig\n",
      "Module layer3.4 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188540>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188540>})\n",
      "Module layer3.4.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1885e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1885e0>})\n",
      "Module layer3.4.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188680>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188680>})\n",
      "Module layer3.4.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188720>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188720>})\n",
      "Module layer3.4.conv1.activation_post_process does not have a qconfig\n",
      "Module layer3.4.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1887c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1887c0>})\n",
      "Module layer3.4.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188860>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188860>})\n",
      "Module layer3.4.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188900>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188900>})\n",
      "Module layer3.4.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1889a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1889a0>})\n",
      "Module layer3.4.conv2.activation_post_process does not have a qconfig\n",
      "Module layer3.4.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188a40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188a40>})\n",
      "Module layer3.4.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188ae0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188ae0>})\n",
      "Module layer3.4.conv3.activation_post_process does not have a qconfig\n",
      "Module layer3.4.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188b80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188b80>})\n",
      "Module layer3.4.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188c20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188c20>})\n",
      "Module layer3.4.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188cc0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188cc0>})\n",
      "Module layer3.4.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188d60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188d60>})\n",
      "Module layer3.4.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188e00>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188e00>})\n",
      "Module layer3.4.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188ea0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188ea0>})\n",
      "Module layer3.4.add.activation_post_process does not have a qconfig\n",
      "Module layer3.5 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188fe0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b188fe0>})\n",
      "Module layer3.5.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189080>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189080>})\n",
      "Module layer3.5.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189120>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189120>})\n",
      "Module layer3.5.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1891c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1891c0>})\n",
      "Module layer3.5.conv1.activation_post_process does not have a qconfig\n",
      "Module layer3.5.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189260>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189260>})\n",
      "Module layer3.5.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189300>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189300>})\n",
      "Module layer3.5.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1893a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1893a0>})\n",
      "Module layer3.5.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189440>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189440>})\n",
      "Module layer3.5.conv2.activation_post_process does not have a qconfig\n",
      "Module layer3.5.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1894e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1894e0>})\n",
      "Module layer3.5.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189580>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189580>})\n",
      "Module layer3.5.conv3.activation_post_process does not have a qconfig\n",
      "Module layer3.5.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189620>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189620>})\n",
      "Module layer3.5.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1896c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1896c0>})\n",
      "Module layer3.5.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189760>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189760>})\n",
      "Module layer3.5.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189800>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189800>})\n",
      "Module layer3.5.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1898a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b1898a0>})\n",
      "Module layer3.5.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189940>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189940>})\n",
      "Module layer3.5.add.activation_post_process does not have a qconfig\n",
      "Module layer4 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189a80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189a80>})\n",
      "Module layer4.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189b20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189b20>})\n",
      "Module layer4.0.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189bc0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189bc0>})\n",
      "Module layer4.0.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189c60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189c60>})\n",
      "Module layer4.0.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189d00>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189d00>})\n",
      "Module layer4.0.conv1.activation_post_process does not have a qconfig\n",
      "Module layer4.0.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189da0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189da0>})\n",
      "Module layer4.0.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189e40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189e40>})\n",
      "Module layer4.0.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189ee0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189ee0>})\n",
      "Module layer4.0.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189f80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b189f80>})\n",
      "Module layer4.0.conv2.activation_post_process does not have a qconfig\n",
      "Module layer4.0.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a020>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a020>})\n",
      "Module layer4.0.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a0c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a0c0>})\n",
      "Module layer4.0.conv3.activation_post_process does not have a qconfig\n",
      "Module layer4.0.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a160>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a160>})\n",
      "Module layer4.0.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a200>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a200>})\n",
      "Module layer4.0.downsample has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a2a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a2a0>})\n",
      "Module layer4.0.downsample.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a340>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a340>})\n",
      "Module layer4.0.downsample.0.activation_post_process does not have a qconfig\n",
      "Module layer4.0.downsample.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a3e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a3e0>})\n",
      "Module layer4.0.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a480>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a480>})\n",
      "Module layer4.0.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a520>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a520>})\n",
      "Module layer4.0.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a5c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a5c0>})\n",
      "Module layer4.0.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a660>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a660>})\n",
      "Module layer4.0.add.activation_post_process does not have a qconfig\n",
      "Module layer4.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a7a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a7a0>})\n",
      "Module layer4.1.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a840>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a840>})\n",
      "Module layer4.1.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a8e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a8e0>})\n",
      "Module layer4.1.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a980>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18a980>})\n",
      "Module layer4.1.conv1.activation_post_process does not have a qconfig\n",
      "Module layer4.1.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18aa20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18aa20>})\n",
      "Module layer4.1.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18aac0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18aac0>})\n",
      "Module layer4.1.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18ab60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18ab60>})\n",
      "Module layer4.1.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18ac00>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18ac00>})\n",
      "Module layer4.1.conv2.activation_post_process does not have a qconfig\n",
      "Module layer4.1.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18aca0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18aca0>})\n",
      "Module layer4.1.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18ad40>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18ad40>})\n",
      "Module layer4.1.conv3.activation_post_process does not have a qconfig\n",
      "Module layer4.1.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18ade0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18ade0>})\n",
      "Module layer4.1.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18ae80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18ae80>})\n",
      "Module layer4.1.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18af20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18af20>})\n",
      "Module layer4.1.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18afc0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18afc0>})\n",
      "Module layer4.1.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b060>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b060>})\n",
      "Module layer4.1.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b100>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b100>})\n",
      "Module layer4.1.add.activation_post_process does not have a qconfig\n",
      "Module layer4.2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b240>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b240>})\n",
      "Module layer4.2.conv1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b2e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b2e0>})\n",
      "Module layer4.2.conv1.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b380>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b380>})\n",
      "Module layer4.2.conv1.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b420>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b420>})\n",
      "Module layer4.2.conv1.activation_post_process does not have a qconfig\n",
      "Module layer4.2.bn1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b4c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b4c0>})\n",
      "Module layer4.2.conv2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b560>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b560>})\n",
      "Module layer4.2.conv2.0 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b600>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b600>})\n",
      "Module layer4.2.conv2.1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b6a0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b6a0>})\n",
      "Module layer4.2.conv2.activation_post_process does not have a qconfig\n",
      "Module layer4.2.bn2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b740>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b740>})\n",
      "Module layer4.2.conv3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b7e0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b7e0>})\n",
      "Module layer4.2.conv3.activation_post_process does not have a qconfig\n",
      "Module layer4.2.bn3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b880>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b880>})\n",
      "Module layer4.2.relu has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b920>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b920>})\n",
      "Module layer4.2.relu1 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b9c0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18b9c0>})\n",
      "Module layer4.2.relu2 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18ba60>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18ba60>})\n",
      "Module layer4.2.relu3 has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18bb00>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18bb00>})\n",
      "Module layer4.2.add has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18bba0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18bba0>})\n",
      "Module layer4.2.add.activation_post_process does not have a qconfig\n",
      "Module avgpool has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18bce0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18bce0>})\n",
      "Module fc has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18bd80>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18bd80>})\n",
      "Module fc.activation_post_process does not have a qconfig\n",
      "Module quant has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18be20>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18be20>})\n",
      "Module quant.activation_post_process does not have a qconfig\n",
      "Module dequant has qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18bec0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x74eb6b18bec0>})\n"
     ]
    }
   ],
   "source": [
    "# 모델의 모든 모듈을 순회합니다.\n",
    "for name, module in model.named_modules():\n",
    "    # 모듈의 qconfig 속성을 확인합니다.\n",
    "    if hasattr(module, \"qconfig\") and module.qconfig is not None:\n",
    "        print(f\"Module {name} has qconfig: {module.qconfig}\")\n",
    "    else:\n",
    "        print(f\"Module {name} does not have a qconfig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inference with the representative dataset (calculate the quantization parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5005 [00:03<5:06:37,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Training Quantization: Calibration done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loader, test_loader = GetDataset(\n",
    "    dataset_name=\"ImageNet\",\n",
    "    device=device,\n",
    "    root=\"data\",\n",
    "    batch_size=256,\n",
    "    num_workers=8,\n",
    ")\n",
    "_, _ = SingleEpochEval(model, train_loader, criterion, \"cuda\", 2)\n",
    "print(\"Post Training Quantization: Calibration done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet_quan(\n",
       "  (conv1): ConvReLU2d(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (bn1): Identity()\n",
       "  (relu): Identity()\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.13715146481990814, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.18796640634536743, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.279589980840683, zero_point=68)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.4388507008552551, zero_point=80)\n",
       "        (1): Identity()\n",
       "      )\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.3759365975856781, zero_point=88\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.12416116148233414, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.13748234510421753, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.42265769839286804, zero_point=99)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.4476096034049988, zero_point=94\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.08788268268108368, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.22612880170345306, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.3209606409072876, zero_point=80)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.35537436604499817, zero_point=71\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.14137469232082367, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.1202661544084549, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.2421475201845169, zero_point=63)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.22529327869415283, zero_point=72)\n",
       "        (1): Identity()\n",
       "      )\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.3000343441963196, zero_point=71\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.07609804719686508, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.08784454315900803, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.22007228434085846, zero_point=83)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.23987625539302826, zero_point=66\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.06940110772848129, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.09450305253267288, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.18998117744922638, zero_point=78)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.21211189031600952, zero_point=64\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.06691539287567139, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1055566817522049, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.19851155579090118, zero_point=78)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.24125923216342926, zero_point=63\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(512, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.14888910949230194, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.08576453477144241, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.22369438409805298, zero_point=57)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): QuantizedConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), scale=0.15099208056926727, zero_point=69)\n",
       "        (1): Identity()\n",
       "      )\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.2706618905067444, zero_point=62\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.08336279541254044, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.0861913338303566, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.16707268357276917, zero_point=73)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.21501322090625763, zero_point=54\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.08428892493247986, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08901028335094452, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.1735074520111084, zero_point=78)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.22984683513641357, zero_point=58\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.10350985080003738, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.10250385850667953, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.19245310127735138, zero_point=63)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.24759505689144135, zero_point=48\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.13960371911525726, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.12216077744960785, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.24546003341674805, zero_point=77)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.27670595049858093, zero_point=58\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.10204049199819565, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.10953602939844131, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.20124030113220215, zero_point=87)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.27553248405456543, zero_point=61\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.10176216810941696, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.08888683468103409, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.34443777799606323, zero_point=69)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): QuantizedConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), scale=0.38033896684646606, zero_point=63)\n",
       "        (1): Identity()\n",
       "      )\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.517268717288971, zero_point=66\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.1671186238527298, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.09841081500053406, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.3345135748386383, zero_point=80)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.447201132774353, zero_point=50\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck_quan(\n",
       "      (conv1): QuantizedConvReLU2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.10310261696577072, zero_point=0)\n",
       "      (bn1): Identity()\n",
       "      (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08324643969535828, zero_point=0, padding=(1, 1))\n",
       "      (bn2): Identity()\n",
       "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.35762038826942444, zero_point=86)\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): QFunctional(\n",
       "        scale=0.38551318645477295, zero_point=69\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): QuantizedLinear(in_features=2048, out_features=1000, scale=0.08425434678792953, zero_point=27, qscheme=torch.per_channel_affine)\n",
       "  (quant): Quantize(scale=tensor([0.3101]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "\n",
    "torch.quantization.convert(model, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert to quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 26.177596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.177596"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Complete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  23 ms\n",
      "Size (MB): 26.177596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 499/2000 [02:45<08:17,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 1.2510, Eval Acc: 85.34%\n",
      "Post Training Quantization: Eval done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(model=model, device=\"cpu\", batch_size=25)\n",
    "print(\"Post Training Quantization: Eval done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026324000000002457"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "26.177596 - 26.151272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41472.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*64*3*3*32*3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConvReLU2d' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 가중치를 가져옵니다.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m __q__conv1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m()\u001b[38;5;241m.\u001b[39mint_repr()\n\u001b[1;32m      3\u001b[0m show_plot(__q__conv1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConvReLU2d' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "# 가중치를 가져옵니다.\n",
    "__q__conv1 = model.conv1.weight().int_repr()\n",
    "show_plot(__q__conv1, \"conv1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-128 127 -2.330078125 30.754166917775493\n"
     ]
    }
   ],
   "source": [
    "# 가중치를 가져옵니다.\n",
    "__q__layer1_0_conv1 = model.layer1[0].conv1.weight().int_repr()\n",
    "show_plot(__q__layer1_0_conv1, \"layer1_0_conv1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-87 127 -0.0043212890625 6.162057292533139\n"
     ]
    }
   ],
   "source": [
    "# 가중치를 가져옵니다.\n",
    "__q__fc = model.fc.weight().int_repr()\n",
    "show_plot(__q__fc, \"fc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet_quan(\n",
       "  (conv1): Conv2d(\n",
       "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
       "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(\n",
       "    64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "        (1): BatchNorm2d(\n",
       "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "        (1): BatchNorm2d(\n",
       "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (3): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "        (1): BatchNorm2d(\n",
       "          1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (3): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (4): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (5): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "        (1): BatchNorm2d(\n",
       "          2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck_quan(\n",
       "      (conv1): Conv2d(\n",
       "        2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv2): Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(\n",
       "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (conv3): Conv2d(\n",
       "        512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (bn3): BatchNorm2d(\n",
       "        2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): ReLU()\n",
       "      (relu2): ReLU()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(\n",
       "    in_features=2048, out_features=1000, bias=True\n",
       "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.quantization as quantization\n",
    "\n",
    "model = resnet50_quan(weights=pretrained_weights_mapping[50]).to(device)\n",
    "\n",
    "# Identify the modules to quantize\n",
    "modules_to_quantize = [model.layer1, model.layer2, model.layer3, model.layer4]\n",
    "\n",
    "# Define qconfig for quantization\n",
    "qconfig = quantization.get_default_qconfig(\"x86\")\n",
    "\n",
    "# Prepare the model for quantization-aware training\n",
    "model.qconfig = qconfig\n",
    "quantization.prepare(model, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee/miniconda3/envs/py312/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1263: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_quan(\n",
      "  (conv1): Conv2d(\n",
      "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (bn1): BatchNorm2d(\n",
      "    64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "        (1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0, bias=False)\n",
      "        (1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0, bias=False)\n",
      "        (1): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (5): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0, bias=False)\n",
      "        (1): QuantizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): BottleNeck_quan(\n",
      "      (conv1): QuantizedConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "      (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "      (bn3): QuantizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (relu1): ReLU()\n",
      "      (relu2): ReLU()\n",
      "      (relu3): ReLU()\n",
      "      (add): QFunctional(\n",
      "        scale=1.0, zero_point=0\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(\n",
      "    in_features=2048, out_features=1000, bias=True\n",
      "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (quant): QuantStub(\n",
      "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "Size (MB): 32.742238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.742238"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Apply quantization to the selected modules\n",
    "for module in modules_to_quantize:\n",
    "    quantization.convert(module, inplace=True)\n",
    "\n",
    "\n",
    "# Print the quantized model\n",
    "print(model)\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
