{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 49/5005 [00:25<42:20,  1.95it/s] \n"
     ]
    }
   ],
   "source": [
    "import torch, time, copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.quantization import prepare, convert\n",
    "from src.utils import *\n",
    "from src.override_resnet import *\n",
    "\n",
    "# All default activation observer is HistogramObserver\n",
    "cases_activation = [\n",
    "    torch.quantization.HistogramObserver.with_args(reduce_range=True),\n",
    "    torch.quantization.HistogramObserver.with_args(reduce_range=False),\n",
    "]\n",
    "# we can use 5 different type of weight observer\n",
    "cases_weight = [\n",
    "    # torch.quantization.HistogramObserver.with_args(dtype=torch.qint8),\n",
    "    # torch.quantization.MinMaxObserver.with_args(dtype=torch.qint8),\n",
    "    # torch.quantization.MovingAverageMinMaxObserver.with_args(dtype=torch.qint8),\n",
    "    torch.quantization.PerChannelMinMaxObserver.with_args(dtype=torch.qint8),\n",
    "    # torch.quantization.MovingAveragePerChannelMinMaxObserver.with_args(dtype=torch.qint8),\n",
    "]\n",
    "\n",
    "\n",
    "def fuse_ALL(model) -> nn.Module:\n",
    "    SingleTimeFlag = False\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__ == ResNet_quan.__name__:\n",
    "            if SingleTimeFlag == True:\n",
    "                raise ValueError(\"ResNet_quan is already fused\")\n",
    "            SingleTimeFlag = True\n",
    "            torch.quantization.fuse_modules(\n",
    "                m,\n",
    "                [\"conv1\", \"bn1\", \"relu\"],\n",
    "                inplace=True,\n",
    "            )\n",
    "\n",
    "        if type(m) == BottleNeck_quan:\n",
    "\n",
    "            torch.quantization.fuse_modules(\n",
    "                m,\n",
    "                [\n",
    "                    [\"conv1\", \"bn1\", \"relu1\"],\n",
    "                    [\"conv2\", \"bn2\", \"relu2\"],\n",
    "                    [\"conv3\", \"bn3\"],\n",
    "                ],\n",
    "                inplace=True,\n",
    "            )\n",
    "            if m.downsample is not None:\n",
    "                torch.quantization.fuse_modules(\n",
    "                    m.downsample,\n",
    "                    [\"0\", \"1\"],\n",
    "                    inplace=True,\n",
    "                )\n",
    "    return model\n",
    "\n",
    "\n",
    "# for case_activation in cases_activation:\n",
    "#     for case_weight in cases_weight:\n",
    "# prepare the model\n",
    "# for i in [120, 121, 122, 123, 124, 125, 126, 127, 128]:\n",
    "\n",
    "model = resnet50_quan(weights=pretrained_weights_mapping[50])\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "# set fuse ############################################################\n",
    "model = fuse_ALL(model)\n",
    "\n",
    "model.qconfig = torch.quantization.QConfig(\n",
    "    activation=torch.quantization.HistogramObserver.with_args(\n",
    "        quant_min=0, quant_max=127, upsample_rate=128\n",
    "    ),\n",
    "    weight=torch.quantization.PerChannelMinMaxObserver.with_args(dtype=torch.qint8),\n",
    ")\n",
    "prepare(model, inplace=True)\n",
    "\n",
    "# calibrate the model ############################################################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loader, _ = GetDataset(\n",
    "    dataset_name=\"ImageNet\",\n",
    "    device=\"cuda\",\n",
    "    root=\"data\",\n",
    "    batch_size=256,\n",
    "    num_workers=8,\n",
    ")\n",
    "_, _ = SingleEpochEval(model, train_loader, criterion, \"cuda\", 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of ResNet_quan(\n",
       "  (conv1): ConvReLU2d(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (activation_post_process): HistogramObserver(min_val=0.0, max_val=57.47951889038086)\n",
       "  )\n",
       "  (bn1): Identity()\n",
       "  (relu): Identity()\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=23.185916900634766)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=25.770811080932617)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-19.876590728759766, max_val=26.70156478881836)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver(min_val=-97.7596435546875, max_val=47.089141845703125)\n",
       "        )\n",
       "        (1): Identity()\n",
       "      )\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-101.61381530761719, max_val=46.206722259521484)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=38.8033561706543)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=36.23356628417969)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-73.47547912597656, max_val=35.29008483886719)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-73.47547912597656, max_val=47.88788604736328)\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=21.010778427124023)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=47.7598876953125)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-51.058990478515625, max_val=136.77781677246094)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-51.058990478515625, max_val=136.77781677246094)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=49.943756103515625)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=60.7420539855957)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-42.36349105834961, max_val=85.54410552978516)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          256, 512, kernel_size=(1, 1), stride=(2, 2)\n",
       "          (activation_post_process): HistogramObserver(min_val=-37.59974670410156, max_val=29.916603088378906)\n",
       "        )\n",
       "        (1): Identity()\n",
       "      )\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-61.173431396484375, max_val=98.26982116699219)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=98.74964141845703)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=45.86955261230469)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-116.9680404663086, max_val=118.4075927734375)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-43.48601150512695, max_val=189.5983123779297)\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=90.25475311279297)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=42.28647232055664)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-68.9100112915039, max_val=32.98360061645508)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-68.9100112915039, max_val=195.80572509765625)\n",
       "      )\n",
       "    )\n",
       "    (3): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=90.17801666259766)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=40.019222259521484)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        128, 512, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-96.45233154296875, max_val=39.00605010986328)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-96.45233154296875, max_val=173.2732391357422)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=52.52427291870117)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=23.123432159423828)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-26.62946891784668, max_val=40.22488021850586)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          512, 1024, kernel_size=(1, 1), stride=(2, 2)\n",
       "          (activation_post_process): HistogramObserver(min_val=-55.097984313964844, max_val=84.97069549560547)\n",
       "        )\n",
       "        (1): Identity()\n",
       "      )\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-50.959083557128906, max_val=104.32044982910156)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=49.506168365478516)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=53.06171798706055)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-130.10812377929688, max_val=61.85935592651367)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-97.32874298095703, max_val=74.18705749511719)\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=27.944297790527344)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=36.3026123046875)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-70.66848754882812, max_val=33.536598205566406)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-70.66848754882812, max_val=59.7813835144043)\n",
       "      )\n",
       "    )\n",
       "    (3): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=44.03508377075195)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=50.60485076904297)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-72.71746063232422, max_val=77.75556945800781)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-72.71746063232422, max_val=78.28230285644531)\n",
       "      )\n",
       "    )\n",
       "    (4): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=67.77351379394531)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=49.148292541503906)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-66.18582916259766, max_val=81.49590301513672)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-66.18582916259766, max_val=83.478271484375)\n",
       "      )\n",
       "    )\n",
       "    (5): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=29.735334396362305)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=52.23920822143555)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        256, 1024, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-64.68840026855469, max_val=35.373878479003906)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-44.34731674194336, max_val=59.4857063293457)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=36.57822036743164)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=35.794151306152344)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        512, 2048, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-53.25920104980469, max_val=102.96998596191406)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(\n",
       "          1024, 2048, kernel_size=(1, 1), stride=(2, 2)\n",
       "          (activation_post_process): HistogramObserver(min_val=-47.96723175048828, max_val=112.69303894042969)\n",
       "        )\n",
       "        (1): Identity()\n",
       "      )\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-64.08436584472656, max_val=121.01289367675781)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=44.19746780395508)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=22.153024673461914)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        512, 2048, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-50.76731872558594, max_val=63.90138244628906)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-39.84968566894531, max_val=113.62860870361328)\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck_quan(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=35.87102127075195)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvReLU2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=29.68022346496582)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (conv3): Conv2d(\n",
       "        512, 2048, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (activation_post_process): HistogramObserver(min_val=-63.55752182006836, max_val=91.19132232666016)\n",
       "      )\n",
       "      (bn3): Identity()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (relu1): Identity()\n",
       "      (relu2): Identity()\n",
       "      (relu3): ReLU()\n",
       "      (add): FloatFunctional(\n",
       "        (activation_post_process): HistogramObserver(min_val=-63.55752182006836, max_val=148.5146484375)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(\n",
       "    in_features=2048, out_features=1000, bias=True\n",
       "    (activation_post_process): HistogramObserver(min_val=-3.829545021057129, max_val=12.295076370239258)\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): HistogramObserver(min_val=-2.1179039478302, max_val=2.640000104904175)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048])\n",
      "2048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([   0.,    0.,    0.,    0.,    0., 2048.,    0.,    0.,    0.,\n",
       "           0.]),\n",
       " array([-0.5       , -0.40000001, -0.30000001, -0.2       , -0.1       ,\n",
       "         0.        ,  0.1       ,  0.2       ,  0.30000001,  0.40000001,\n",
       "         0.5       ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram = getattr(model.layer4.qconfig.activation.p(), \"histogram\")\n",
    "print(histogram.shape)\n",
    "#  = model.layer1[0].conv1.\n",
    "print(len(histogram))\n",
    "\n",
    "plt.hist(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert the model ############################################################\n",
    "model.to(\"cpu\")\n",
    "convert(model, inplace=True)\n",
    "\n",
    "# evaluate the model ############################################################\n",
    "\n",
    "_batch_size = 32\n",
    "_, test_loader = GetDataset(\n",
    "    dataset_name=\"ImageNet\",\n",
    "    device=\"cpu\",\n",
    "    root=\"data\",\n",
    "    batch_size=_batch_size,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "eval_loss, eval_acc = SingleEpochEval(\n",
    "    model=model,\n",
    "    testloader=test_loader,\n",
    "    criterion=criterion,\n",
    "    device=\"cpu\",\n",
    "    limit=10,\n",
    ")\n",
    "model_size = get_size_of_model(model)\n",
    "inference_time = run_benchmark(model, test_loader, \"cpu\", 10)\n",
    "print(\"------------------------------------------------------------\")\n",
    "# print(f\"case_activation: {case_activation}\")\n",
    "# print(f\"case_upsample_rate: {i}\")\n",
    "print(f\"Model Size: {model_size:.2f}MB\")\n",
    "print(f\"Inference Time: {inference_time:.2f}ms\")\n",
    "print(f\"Eval Loss: {eval_loss:.4f}\")\n",
    "print(f\"Eval Acc: {eval_acc:.3f}%\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
