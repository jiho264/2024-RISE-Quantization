{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time, copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.quantization import prepare, convert\n",
    "from src.utils import *\n",
    "from src.override_resnet import *\n",
    "\n",
    "\n",
    "model = resnet50_quan(weights=pretrained_weights_mapping[50])\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "# set fuse ############################################################\n",
    "model = fuse_ALL(model)\n",
    "\n",
    "model.qconfig = torch.quantization.QConfig(\n",
    "    activation=torch.quantization.HistogramObserver.with_args(reduce_range=True),\n",
    "    weight=torch.quantization.PerChannelMinMaxObserver.with_args(dtype=torch.qint8),\n",
    ")\n",
    "prepare(model, inplace=True)\n",
    "\n",
    "# calibrate the model ############################################################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loader, _ = GetDataset(\n",
    "    dataset_name=\"ImageNet\",\n",
    "    device=\"cuda\",\n",
    "    root=\"data\",\n",
    "    batch_size=256,\n",
    "    num_workers=8,\n",
    ")\n",
    "print(SingleEpochEval(model, train_loader, criterion, \"cuda\", 50))\n",
    "\n",
    "# for name, module in model.named_modules():\n",
    "#     print(name, module)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.0.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(39.0166, device='cuda:0')\n",
      "\n",
      "layer1.1.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(37.5907, device='cuda:0')\n",
      "\n",
      "layer1.2.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(137.5625, device='cuda:0')\n",
      "\n",
      "layer2.0.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(97.2317, device='cuda:0')\n",
      "\n",
      "layer2.1.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(189.9802, device='cuda:0')\n",
      "\n",
      "layer2.2.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(190.2122, device='cuda:0')\n",
      "\n",
      "layer2.3.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(167.3941, device='cuda:0')\n",
      "\n",
      "layer3.0.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(103.5171, device='cuda:0')\n",
      "\n",
      "layer3.1.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(70.9293, device='cuda:0')\n",
      "\n",
      "layer3.2.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(57.2622, device='cuda:0')\n",
      "\n",
      "layer3.3.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(76.7407, device='cuda:0')\n",
      "\n",
      "layer3.4.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(84.4516, device='cuda:0')\n",
      "\n",
      "layer3.5.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(54.3113, device='cuda:0')\n",
      "\n",
      "layer4.0.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(126.2963, device='cuda:0')\n",
      "\n",
      "layer4.1.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(108.2061, device='cuda:0')\n",
      "\n",
      "layer4.2.through torch.Size([2048])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(116.3469, device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "for name, module in model.named_modules():\n",
    "    if (\n",
    "        len(name) > 2\n",
    "        and name[-7:] == \"through\"\n",
    "        and hasattr(module, \"activation_post_process\")\n",
    "    ):\n",
    "        # if name == \"act_obs\":\n",
    "        print(f\"{name}\", end=\" \")\n",
    "\n",
    "        _hist = list()\n",
    "        print(module.activation_post_process.histogram.shape)\n",
    "        tmp = module.activation_post_process.histogram.to(\"cpu\").numpy()\n",
    "        # for x in module.activation_post_process.get_tensor_value():\n",
    "        #     _hist.append(torch.tensor(x).to(\"cpu\"))\n",
    "\n",
    "        #     print(torch.tensor(x).to(\"cpu\").numpy().shape, end=\" \")\n",
    "\n",
    "        # _hist = np.array(_hist).flatten()\n",
    "\n",
    "        # cnt = 1\n",
    "        # for i in _hist.shape:\n",
    "        #     cnt *= i\n",
    "\n",
    "        # tmp = cnt * 4 / 1024 / 1024, \"MB\"\n",
    "        # print(tmp)\n",
    "        print(module.activation_post_process.min_val)\n",
    "        print(module.activation_post_process.max_val)\n",
    "        print(\"\")\n",
    "        # plt.hist(tmp)\n",
    "        # plt.title(name)\n",
    "        # # plt.yscale(\"log\")\n",
    "        # plt.xlabel(\"Activation value\")\n",
    "        # plt.ylabel(\"Frequency\")\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
