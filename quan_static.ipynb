{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.utils import *\n",
    "from src.override_resnet import *\n",
    "\n",
    "class Args: \n",
    "    \"\"\"Main function for training ResNet model.\n",
    "\n",
    "    Args:\n",
    "        --num_layers (int): number of layers\n",
    "        --dataset (str): name of the dataset\n",
    "        --lr (float): learning rate\n",
    "        --momentum (float): momentum\n",
    "        --batch_size (int): batch size\n",
    "        --num_epochs (int): number of epochs\n",
    "        --save_every (int): save model every n epochs\n",
    "        --qat (bool): Enable Quantization Aware Training\n",
    "        --only_eval (bool): only evaluation mode\n",
    "        --verbose (bool): print mini-batch loss and accuracy\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    num_layers = 50\n",
    "    dataset = \"ImageNet\"\n",
    "    lr = 0.001\n",
    "    momentum = 0.9\n",
    "    batch_size = 128\n",
    "    num_epochs = 10\n",
    "    save_every = 1\n",
    "    qat = True\n",
    "    only_eval = True\n",
    "    verbose = True\n",
    "    qat_method = \"static\"\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Static Quantization enabled\n",
      "No savepoint found. Starting from Pretrained Model\n",
      "evaluate acc of pretrained model.\n"
     ]
    }
   ],
   "source": [
    "# %% Load the ResNet-50 model\n",
    "if args.qat == True:\n",
    "    if args.qat_method == \"dynamic\":\n",
    "        # case 1 : Dynamic Quantization\n",
    "        device = \"cpu\"\n",
    "        model = resnet50_quan(\n",
    "            weights=pretrained_weights_mapping[args.num_layers]\n",
    "        ).to(device)\n",
    "        quantized_model = torch.quantization.quantize_dynamic(\n",
    "            model, {torch.nn.Linear}, dtype=torch.qint8\n",
    "        )\n",
    "        model = quantized_model\n",
    "        print(\"----------Dynamic Quantization enabled\")\n",
    "    elif args.qat_method == \"static\":\n",
    "        device = \"cpu\"\n",
    "        model = resnet50_quan(weights=pretrained_weights_mapping[args.num_layers]).to(\n",
    "            device\n",
    "        )\n",
    "        # case 2 : Static Quantization\n",
    "        print(\"----------Static Quantization enabled\")\n",
    "\n",
    "    elif args.qat_method == \"qat\":\n",
    "        # case 3 : Quantization Aware Training\n",
    "        print(\"----------Quantization Aware Training enabled\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid QAT method\")\n",
    "\n",
    "else:\n",
    "    device = str(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    model = layers_mapping[args.num_layers](\n",
    "        weights=pretrained_weights_mapping[args.num_layers]\n",
    "    ).to(device)\n",
    "\n",
    "if args.qat == True:\n",
    "    _folder_path = f\"resnet{args.num_layers}_{args.dataset}_QAT\"\n",
    "else:\n",
    "    _folder_path = f\"resnet{args.num_layers}_{args.dataset}\"\n",
    "\n",
    "_file_name = f\"resnet{args.num_layers}_{args.dataset}_epoch\"  # resnet18_cifar10_epoch{epoch}.pth\n",
    "\n",
    "_latest_epoch = CheckPointLoader(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    folder_path=_folder_path,\n",
    "    file_name=_file_name,\n",
    "    only_eval=args.only_eval,\n",
    ")\n",
    "\n",
    "# %%Set up training and evaluation processes\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "train_loader, test_loader = GetDataset(\n",
    "    dataset_name=args.dataset,\n",
    "    device=device,\n",
    "    root=\"data\",\n",
    "    batch_size=args.batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mfuse_model()\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mqconfig \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mget_default_qconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx86_64\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.fuse_model()\n",
    "model.qconfig = torch.quantization.get_default_qconfig(\"x86_64\")\n",
    "torch.quantization.prepare(model, inplace=True)\n",
    "\n",
    "# 첫 번째 보정\n",
    "print(\"Post Training Quantization Prepare: Inserting Observers\")\n",
    "print(\n",
    "    \"\\n Inverted Residual Block:After observer insertion \\n\\n\", model.features[1].conv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Training and evaluation\n",
    "# 1cycle learning rate schedule\n",
    "print(\"Post Training Quantization: Calibration done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.quantization.convert(model, inplace=True)\n",
    "print(\"Post Training Quantization: Convert done\")\n",
    "print(\n",
    "    \"\\n Inverted Residual Block: After fusion and quantization, note fused modules: \\n\\n\",\n",
    "    model.features[1].conv,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Training and evaluation\n",
    "# 1cycle learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
