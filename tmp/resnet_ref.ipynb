{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python version : 3.12.1 | packaged by Anaconda, Inc. | (main, Jan 19 2024, 15:51:05) [GCC 11.2.0]\n",
      "torch version :  2.2.1\n",
      "cuda available :  True\n",
      "NVIDIA GeForce RTX 3090\n",
      "cudnn ver :  8902\n",
      "cudnn enabled: True\n",
      "Using device: cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch, sys, time, os\n",
    "\n",
    "print(\"\")\n",
    "print(\"Python version :\", sys.version)\n",
    "print(\"torch version : \", torch.__version__)\n",
    "print(\"cuda available : \", torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(\"cudnn ver : \", torch.backends.cudnn.version())\n",
    "print(\"cudnn enabled:\", torch.backends.cudnn.enabled)\n",
    "device = str(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "BATCH = 128\n",
    "SAVE_MODEL_EVERY_N_EPOCH = 5\n",
    "CONT_FROM_SAVE = \"latest\"  # 0, \"latest\", \"epoch_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing from latest save 15 epochs\n"
     ]
    }
   ],
   "source": [
    "# use save?\n",
    "\n",
    "if CONT_FROM_SAVE == 0:\n",
    "    print(\"Starting from scratch\")\n",
    "elif CONT_FROM_SAVE == \"latest\":\n",
    "\n",
    "    folder_path = \"resnet18_cifar10\"\n",
    "    file_extension = \".pth\"\n",
    "\n",
    "    # Get a list of all pth files in the folder\n",
    "    pth_files = [file for file in os.listdir(folder_path) if file.endswith(file_extension)]\n",
    "    # Sort the pth files based on the epoch number\n",
    "    sorted_files = sorted(\n",
    "        pth_files, key=lambda x: int(x.split(\"_epoch\")[1].split(\".pth\")[0])\n",
    "    )\n",
    "\n",
    "    # Get the file with the highest epoch number\n",
    "    latest_file = sorted_files[-1]\n",
    "\n",
    "    # Extract the epoch number from the file name\n",
    "    latest_epoch = int(latest_file.split(\"_epoch\")[1].split(\".pth\")[0])\n",
    "\n",
    "    print(f\"Continuing from latest save {latest_epoch} epochs\")\n",
    "\n",
    "else:\n",
    "    print(f\"Continuing from {CONT_FROM_SAVE} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "import torchvision.models.resnet as resnet\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Load the ResNet-50 model\n",
    "model = resnet18(weights=resnet.ResNet18_Weights.DEFAULT).to(device)\n",
    "\n",
    "# Set up training and evaluation processes\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    pin_memory_device=device,\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    pin_memory_device=device,\n",
    ")\n",
    "\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SingleEpochTrain(\n",
    "    model, trainloader, criterion, optimizer, device, verb=True\n",
    ") -> tuple:\n",
    "    # Training loop\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "    for i, (images, labels) in enumerate(trainloader, start=0):\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        if i % 100 == 0 and verb == True:\n",
    "            now_time = time.time()\n",
    "            print(\n",
    "                f\"Batch {str(i).rjust(len(str(len(trainloader))))}/{len(trainloader)} ({now_time - start_time:.2f}s) | train_loss: {loss.item():.4f} | train_acc: {correct/total*100:.2f}%\"\n",
    "            )\n",
    "\n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    train_acc = 100.0 * correct / total\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SingleEpochEval(\n",
    "    model, testloader, criterion, device\n",
    ") -> tuple:\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(trainloader, start=0):\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    eval_loss = running_loss / len(testloader)\n",
    "    eval_acc = 100.0 * correct / total\n",
    "\n",
    "    return eval_loss, eval_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100 (4.19s) | train_loss: 1.5430 | train_acc: 56.61% | eval_loss: 3.7743 | eval_acc: 73.74%\n",
      "Epoch   2/100 (4.17s) | train_loss: 0.7532 | train_acc: 73.88% | eval_loss: 2.7610 | eval_acc: 80.70%\n",
      "Epoch   3/100 (4.24s) | train_loss: 0.5934 | train_acc: 79.29% | eval_loss: 2.1294 | eval_acc: 85.30%\n",
      "Epoch   4/100 (4.37s) | train_loss: 0.4801 | train_acc: 83.25% | eval_loss: 1.6696 | eval_acc: 88.78%\n",
      "Epoch   5/100 (4.23s) | train_loss: 0.3911 | train_acc: 86.37% | eval_loss: 1.1826 | eval_acc: 92.45%\n",
      "Epoch   6/100 (4.23s) | train_loss: 0.3082 | train_acc: 89.30% | eval_loss: 0.8549 | eval_acc: 94.81%\n",
      "Epoch   7/100 (4.21s) | train_loss: 0.2395 | train_acc: 91.73% | eval_loss: 0.6339 | eval_acc: 96.13%\n",
      "Epoch   8/100 (4.15s) | train_loss: 0.1816 | train_acc: 93.72% | eval_loss: 0.4057 | eval_acc: 97.68%\n",
      "Epoch   9/100 (4.23s) | train_loss: 0.1420 | train_acc: 95.03% | eval_loss: 0.2725 | eval_acc: 98.53%\n",
      "Epoch  10/100 (4.13s) | train_loss: 0.1161 | train_acc: 96.04% | eval_loss: 0.1974 | eval_acc: 98.99%\n",
      "Epoch  11/100 (4.14s) | train_loss: 0.0942 | train_acc: 96.64% | eval_loss: 0.1630 | eval_acc: 99.09%\n",
      "Epoch  12/100 (4.20s) | train_loss: 0.0797 | train_acc: 97.20% | eval_loss: 0.1286 | eval_acc: 99.28%\n",
      "Epoch  13/100 (4.15s) | train_loss: 0.0674 | train_acc: 97.65% | eval_loss: 0.0993 | eval_acc: 99.47%\n",
      "Epoch  14/100 (4.14s) | train_loss: 0.0606 | train_acc: 97.89% | eval_loss: 0.0804 | eval_acc: 99.58%\n",
      "Epoch  15/100 (4.18s) | train_loss: 0.0496 | train_acc: 98.22% | eval_loss: 0.0587 | eval_acc: 99.71%\n",
      "Epoch  16/100 (4.15s) | train_loss: 0.0469 | train_acc: 98.31% | eval_loss: 0.0645 | eval_acc: 99.65%\n",
      "Epoch  17/100 (4.12s) | train_loss: 0.0452 | train_acc: 98.44% | eval_loss: 0.0556 | eval_acc: 99.67%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m\n\u001b[1;32m      4\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m SingleEpochTrain(\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      7\u001b[0m     trainloader\u001b[38;5;241m=\u001b[39mtrainloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     verb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m eval_loss, eval_acc \u001b[38;5;241m=\u001b[39m \u001b[43mSingleEpochEval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(epoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrjust(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(NUM_EPOCHS)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms) | train_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | train_acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% | eval_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | eval_acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m )\n",
      "Cell \u001b[0;32mIn[29], line 11\u001b[0m, in \u001b[0;36mSingleEpochEval\u001b[0;34m(model, testloader, criterion, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Forward pass\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_profile_name\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    628\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/torch/autograd/profiler.py:593\u001b[0m, in \u001b[0;36mrecord_function.__init__\u001b[0;34m(self, name, args)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mrecord_function\u001b[39;00m(_ContextDecorator):\n\u001b[1;32m    557\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager/function decorator that adds a label to a code block/function when running autograd profiler.\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m    It is useful when tracing the code profile.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m \n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, args: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    594\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    595\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m args\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):  # Change the number of epochs as needed\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = SingleEpochTrain(\n",
    "        model=model,\n",
    "        trainloader=trainloader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        verb=False,\n",
    "    )\n",
    "    eval_loss, eval_acc = SingleEpochEval(model=model, testloader=testloader, criterion=criterion, device=device)\n",
    "    end_time = time.time()\n",
    "    print(\n",
    "        f\"Epoch {str(epoch + 1).rjust(len(str(NUM_EPOCHS)))}/{NUM_EPOCHS} ({end_time - start_time:.2f}s) | train_loss: {train_loss:.4f} | train_acc: {train_acc:.2f}% | eval_loss: {eval_loss:.4f} | eval_acc: {eval_acc:.2f}%\"\n",
    "    )\n",
    "    if (epoch + 1) % SAVE_MODEL_EVERY_N_EPOCH == 0:\n",
    "        torch.save(\n",
    "            model.state_dict(), f\"resnet18_cifar10/resnet18_cifar10_epoch{epoch+1}.pth\"\n",
    "        )\n",
    "\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
