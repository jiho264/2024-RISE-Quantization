{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.utils import *\n",
    "from src.override_resnet import *\n",
    "\n",
    "\n",
    "class Args:\n",
    "    arch = 50\n",
    "    dataset = \"ImageNet\"\n",
    "    # dataset = \"CIFAR100\"\n",
    "    lr = 0.001\n",
    "    momentum = 0.9\n",
    "    batch = 16\n",
    "    epochs = 10\n",
    "    save_every = 1\n",
    "    quan = \"qat\"\n",
    "    only_eval = True\n",
    "    verbose = True\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(model, img_loader):\n",
    "    elapsed = 0\n",
    "    model.eval()\n",
    "    num_batches = 1\n",
    "    # 이미지 배치들 이용하여 스크립트된 모델 실행\n",
    "    for i, (images, target) in enumerate(img_loader):\n",
    "        if i < num_batches:\n",
    "            start = time.time()\n",
    "            output = model(images)\n",
    "            end = time.time()\n",
    "            elapsed = elapsed + (end - start)\n",
    "        else:\n",
    "            break\n",
    "    num_images = images.size()[0] * num_batches\n",
    "\n",
    "    print(\"Elapsed time: %3.0f ms\" % (elapsed / num_images * 1000))\n",
    "    return elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_model(model) -> nn.Module:\n",
    "    flag = False\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__ == ResNet_quan.__name__:\n",
    "            if flag == True:\n",
    "                raise ValueError(\"ResNet_quan is already fused\")\n",
    "            flag = True\n",
    "            torch.quantization.fuse_modules(\n",
    "                m,\n",
    "                [\"conv1\", \"bn1\", \"relu\"],\n",
    "                inplace=True,\n",
    "            )\n",
    "\n",
    "        if type(m) == BottleNeck_quan:\n",
    "            torch.quantization.fuse_modules(\n",
    "                m,\n",
    "                [\n",
    "                    [\"conv1\", \"bn1\", \"relu1\"],\n",
    "                    [\"conv2\", \"bn2\", \"relu2\"],\n",
    "                    [\"conv3\", \"bn3\"],\n",
    "                ],\n",
    "                inplace=True,\n",
    "            )\n",
    "            if m.downsample is not None:\n",
    "                torch.quantization.fuse_modules(\n",
    "                    m.downsample,\n",
    "                    [\"0\", \"1\"],\n",
    "                    inplace=True,\n",
    "                )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% my code\n",
    "\n",
    "args = Args()\n",
    "# %% Load the ResNet-50 model\n",
    "if args.quan == \"fp32\":\n",
    "    # case 0 : no quantization case\n",
    "    print(\"----------No quantization enabled\")\n",
    "    device = str(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    model = layers_mapping[args.arch](\n",
    "        weights=pretrained_weights_mapping[args.arch]\n",
    "    ).to(device)\n",
    "\n",
    "elif args.quan == \"dynamic\":\n",
    "    # case 1 : Dynamic Quantization\n",
    "    print(\"----------Dynamic Quantization enabled\")\n",
    "    device = \"cuda\"\n",
    "    model = resnet50_quan(weights=pretrained_weights_mapping[args.arch]).to(device)\n",
    "    quantized_model = torch.quantization.quantize_dynamic(\n",
    "        model, {torch.nn.Linear}, dtype=torch.qint8\n",
    "    )\n",
    "    model = quantized_model\n",
    "\n",
    "elif args.quan == \"static\":\n",
    "    # case 2 : Static Quantization\n",
    "    print(\"----------Static Quantization enabled\")\n",
    "    device = \"cpu\"\n",
    "    model = resnet50_quan(weights=pretrained_weights_mapping[args.arch]).to(device)\n",
    "\n",
    "elif args.quan == \"qat\":\n",
    "    # case 3 : Quantization Aware Training\n",
    "    print(\"----------Quantization Aware Training enabled\")\n",
    "    device = \"cpu\"\n",
    "    model = resnet50_quan(weights=pretrained_weights_mapping[args.arch]).to(device)\n",
    "else:\n",
    "    raise ValueError(\"Invalid quantization method\")\n",
    "\n",
    "_folder_path = f\"resnet{args.arch}_{args.dataset}\" + \"_\" + args.quan\n",
    "_file_name = (\n",
    "    f\"resnet{args.arch}_{args.dataset}_epoch\"  # resnet18_cifar10_epoch{epoch}.pth\n",
    ")\n",
    "\n",
    "# %%Set up training and evaluation processes\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "# device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "train_loader, test_loader = GetDataset(\n",
    "    dataset_name=args.dataset,\n",
    "    device=device,\n",
    "    root=\"data\",\n",
    "    batch_size=64,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순히 양자화 설정 방법을 변경하는 것만으로도 정확도가 67.3%를 넘을 정도로 향상이 되었습니다! 그럼에도 이 수치는 위에서 구한 기준값 71.9%에서 4퍼센트나 낮은 수치입니다. 이제 양자화 자각 학습을 시도해 봅시다.\n",
    "\n",
    "# 5. 양자화 자각 학습(Quantization-aware training)\n",
    "- 양자화 자각 학습(QAT)은 일반적으로 가장 높은 정확도를 제공하는 양자화 방법입니다. 모든 가중치화 활성값은 QAT로 인해 학습 도중에 순전파와 역전파를 도중 《가짜 양자화》됩니다. \n",
    "- 이는 float값이 int8 값으로 반올림하는 것처럼 흉내를 내지만, 모든 계산은 여전히 부동소수점 숫자로 계산을 합니다. 그래서 결국 훈련 동안의 모든 가중치 조정은 모델이 양자화될 것이라는 사실을 《자각》한 채로 이루어지게 됩니다. \n",
    "- 그래서 QAT는 양자화가 이루어지고 나면 동적 양자화나 학습 전 정적 양자화보다 대체로 더 높은 정확도를 보여줍니다.\n",
    "\n",
    "- 실제로 QAT가 이루어지는 전체 흐름은 이전과 매우 유사합니다:\n",
    "\n",
    "  - 이전과 같은 모델을 사용할 수 있습니다. 양자화 자각 학습을 위한 추가적인 준비는 필요 없습니다.\n",
    "\n",
    "  - 가중치와 활성값 뒤에 어떤 종류의 가짜 양자화를 사용할 것인지 명시하는 qconfig 의 사용이 필요합니다. Observer를 명시하는 것 대신에 말이죠.\n",
    "\n",
    "먼저 학습 함수부터 정의합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fuse_model(model)\n",
    "\n",
    "model.qconfig = torch.quantization.get_default_qconfig(\"x86\")\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.quantization.prepare_qat(model, inplace=True)\n",
    "print(\n",
    "    \"Inverted Residual Block: After preparation for QAT, note fake-quantization modules \\n\",\n",
    "    model.layer1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(8):\n",
    "    # _, _ = SingleEpochTrain(model, train_loader, criterion, optimizer, device, verb=False)\n",
    "    _, _ = SingleEpochTrain(model, test_loader, criterion, optimizer, device, verb=False)\n",
    "    if epoch > 3:\n",
    "        # Freeze quantizer parameters\n",
    "        model.apply(torch.quantization.disable_observer)\n",
    "    if epoch > 2:\n",
    "        # Freeze batch norm mean and variance estimates\n",
    "        model.apply(torch.nn.intrinsic.qat.freeze_bn_stats)\n",
    "\n",
    "    tmp_model = torch.quantization.convert(model.eval(), inplace=False)\n",
    "    eval_loss, eval_acc = SingleEpochEval(tmp_model, test_loader, criterion, device)\n",
    "    print(f\"epoch {epoch} : eval_loss {eval_loss}, eval_acc {eval_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_benchmark(model, test_loader)\n",
    "print_size_of_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
