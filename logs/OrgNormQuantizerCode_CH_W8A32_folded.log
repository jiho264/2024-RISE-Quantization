Case: [ resnet18_OrgNormQuantizerCode_CH_W8A32_folded ]
    - {'arch': 'resnet18', 'batch_size': 128, 'num_samples': 1024, 'fold': True}
    - weight params: {'scheme': 'OrgNormQuantizerCode', 'per_channel': True, 'dstDtype': 'INT8'}
    - activation params: {}

Replace to QuantModule
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
Qparams computing done!
    QuantModule: conv1, torch.Size([64, 3, 7, 7])
    QuantModule: layer1.0.conv1, torch.Size([64, 64, 3, 3])
    QuantModule: layer1.0.conv2, torch.Size([64, 64, 3, 3])
    QuantModule: layer1.1.conv1, torch.Size([64, 64, 3, 3])
    QuantModule: layer1.1.conv2, torch.Size([64, 64, 3, 3])
    QuantModule: layer2.0.conv1, torch.Size([128, 64, 3, 3])
    QuantModule: layer2.0.conv2, torch.Size([128, 128, 3, 3])
    QuantModule: layer2.0.downsample.0, torch.Size([128, 64, 1, 1])
    QuantModule: layer2.1.conv1, torch.Size([128, 128, 3, 3])
    QuantModule: layer2.1.conv2, torch.Size([128, 128, 3, 3])
    QuantModule: layer3.0.conv1, torch.Size([256, 128, 3, 3])
    QuantModule: layer3.0.conv2, torch.Size([256, 256, 3, 3])
    QuantModule: layer3.0.downsample.0, torch.Size([256, 128, 1, 1])
    QuantModule: layer3.1.conv1, torch.Size([256, 256, 3, 3])
    QuantModule: layer3.1.conv2, torch.Size([256, 256, 3, 3])
    QuantModule: layer4.0.conv1, torch.Size([512, 256, 3, 3])
    QuantModule: layer4.0.conv2, torch.Size([512, 512, 3, 3])
    QuantModule: layer4.0.downsample.0, torch.Size([512, 256, 1, 1])
    QuantModule: layer4.1.conv1, torch.Size([512, 512, 3, 3])
    QuantModule: layer4.1.conv2, torch.Size([512, 512, 3, 3])
    QuantModule: fc, torch.Size([1000, 512])
Total QuantModule: 21, Folded BN layers : 20
    Quantized model Evaluation accuracy on 50000 images, 69.788%
Total time: 162.38 sec
