
Case: [ resnet18_AbsMaxQuantizer_Layer_W4A32_BNFold ]
    - arch: resnet18
    - batch_size: 128
    - num_samples: 1024
    - folding: True

- weight params:
    - scheme: AbsMaxQuantizer
    - dstDtype: INT4
    - per_channel: False

- activation params:

Replace to QuantModule
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
    Conv2d <- BatchNorm2d    BN Folded!
Qparams computing done!
    QuantModule: conv1, torch.Size([64, 3, 7, 7])
    QuantModule: layer1.0.conv1, torch.Size([64, 64, 3, 3])
    QuantModule: layer1.0.conv2, torch.Size([64, 64, 3, 3])
    QuantModule: layer1.1.conv1, torch.Size([64, 64, 3, 3])
    QuantModule: layer1.1.conv2, torch.Size([64, 64, 3, 3])
    QuantModule: layer2.0.conv1, torch.Size([128, 64, 3, 3])
    QuantModule: layer2.0.conv2, torch.Size([128, 128, 3, 3])
    QuantModule: layer2.0.downsample.0, torch.Size([128, 64, 1, 1])
    QuantModule: layer2.1.conv1, torch.Size([128, 128, 3, 3])
    QuantModule: layer2.1.conv2, torch.Size([128, 128, 3, 3])
    QuantModule: layer3.0.conv1, torch.Size([256, 128, 3, 3])
    QuantModule: layer3.0.conv2, torch.Size([256, 256, 3, 3])
    QuantModule: layer3.0.downsample.0, torch.Size([256, 128, 1, 1])
    QuantModule: layer3.1.conv1, torch.Size([256, 256, 3, 3])
    QuantModule: layer3.1.conv2, torch.Size([256, 256, 3, 3])
    QuantModule: layer4.0.conv1, torch.Size([512, 256, 3, 3])
    QuantModule: layer4.0.conv2, torch.Size([512, 512, 3, 3])
    QuantModule: layer4.0.downsample.0, torch.Size([512, 256, 1, 1])
    QuantModule: layer4.1.conv1, torch.Size([512, 512, 3, 3])
    QuantModule: layer4.1.conv2, torch.Size([512, 512, 3, 3])
    QuantModule: fc, torch.Size([1000, 512])
Total QuantModule: 21, Folded BN layers : 20
    Quantized model Evaluation accuracy on 50000 images, 0.246%
Total time: 45.77 sec
